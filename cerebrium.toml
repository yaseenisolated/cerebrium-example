[cerebrium.deployment]
name = "my-first-project"
python_version = "3.13"
docker_base_image_url = "nvidia/cuda:12.1.1-runtime-ubuntu22.04"
disable_auth = false
include = ['./*', 'main.py', 'cerebrium.toml']
exclude = ['.*']
shell_commands = ["export HF_HOME=/cortex/.cache/huggingface", "python3 -c \"import torch; from diffusers import StableDiffusionPipeline; StableDiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-2-1', torch_dtype=torch.float16)\""]

[cerebrium.hardware]
cpu = 2.0
memory = 12.0
compute = "CPU"

[cerebrium.scaling]
min_replicas = 0
max_replicas = 5
cooldown = 30
replica_concurrency = 1
response_grace_period = 900
scaling_metric = "concurrency_utilization"
scaling_target = 100
scaling_buffer = 0
roll_out_duration_seconds = 0


[cerebrium.runtime.custom]
port = 8192
healthcheck_endpoint = "/health"
readycheck_endpoint = "/ready"
dockerfile_path = "./Dockerfile"
